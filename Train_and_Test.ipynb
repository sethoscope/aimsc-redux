{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Train and Test.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMIth4lboAZRhyQzZegODUw"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "8_zL0jUrGHFu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "import os.path\n",
        "MOUNT_POINT='/content/drive'\n",
        "if not os.path.exists(MOUNT_POINT):\n",
        "    drive.mount(MOUNT_POINT)\n",
        "PROJECT_ROOT = os.path.join(MOUNT_POINT, 'My Drive/aimsc-redux')\n",
        "MUSIC_DIR = os.path.join(PROJECT_ROOT, 'music')\n",
        "%cd {MUSIC_DIR}\n",
        "!pip install torchaudio"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oE17HsXjF2QH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import logging\n",
        "from argparse import ArgumentParser, ArgumentDefaultsHelpFormatter, FileType\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset\n",
        "import torchaudio\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import yaml\n",
        "import time\n",
        "import os\n",
        "\n",
        "\n",
        "# assumptions:\n",
        "#   all inputs have the same sampling frequency\n",
        "#   all songs are long enough for the segment size we want\n",
        "class AudioDataset(Dataset):\n",
        "    def __init__(self, songs, music_dir, segment_length, segments_per_song, downsample_rate):\n",
        "        self.songs = songs\n",
        "        self.music_dir = music_dir\n",
        "        self.segments_per_song = segments_per_song\n",
        "        self.segment_length = segment_length # audio samples per datum\n",
        "        self.downsample_rate = downsample_rate\n",
        "\n",
        "        labels = sorted(list(set(s.label for s in songs)))   # all the labels\n",
        "        self.label_number_map = {v:i for i,v in enumerate(labels)}   # {'foo':0, 'bar':1, ...}\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        song_index = int(i / self.segments_per_song)\n",
        "        segment_index = i % self.segments_per_song\n",
        "        song = self.songs[song_index]\n",
        "        audio = song.audio(segment_index, self.music_dir, self.segment_length,\n",
        "                           self.segments_per_song, self.downsample_rate)\n",
        "        \n",
        "        return audio, self.label_number_map[song.label]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.songs * self.segments_per_song)\n",
        "\n",
        "class Song():\n",
        "    def __init__(self, fields):\n",
        "        self.fields = fields\n",
        "        self.__dict__.update(fields)\n",
        "\n",
        "    def __repr__(self):\n",
        "        return 'Song<{}>'.format(str(list(self.fields.values())))\n",
        "\n",
        "    def audio(self, segment_index, music_dir, segment_length, segments_per_song, downsample_rate):\n",
        "        (audio, samplingfreq) = torchaudio.load(os.path.join(music_dir, self.filename))\n",
        "        audio = audio.permute(1, 0) # 1×N ~ N×1\n",
        "        # downsample, and keep the amount amount of data specified\n",
        "        if audio.size()[0] / downsample_rate < segments_per_song * segment_length:\n",
        "            logging.error(f'song too short! length: {audio.size()[0]}, need {segments_per_song * segment_length * downsample_rate}')\n",
        "        return audio[segment_index * segment_length * downsample_rate\n",
        "                     : (segment_index+1) * segment_length * downsample_rate\n",
        "                     : downsample_rate].permute(1, 0)\n",
        "\n",
        "class ConvBn():\n",
        "    def __init__(self, in_channels, out_channels, *args, **kwargs):\n",
        "        self.conv = nn.Conv1d(in_channels, out_channels, *args, **kwargs)\n",
        "        self.bn = nn.BatchNorm1d(out_channels)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return F.relu(self.bn(self.conv(x)))\n",
        "\n",
        "class ManyConvMaxPool():\n",
        "    def __init__(self, conv_count, maxpool_kernel, in_channels, out_channels, *args, **kwargs):\n",
        "        self.pool = nn.MaxPool1d(maxpool_kernel)\n",
        "        self.conv_layers = [ConvBn(in_channels, out_channels, *args, **kwargs)]\n",
        "        for _ in range(conv_count - 1):\n",
        "            self.conv_layers.append(ConvBn(out_channels, out_channels, *args, **kwargs))\n",
        "\n",
        "    def forward(self, x):\n",
        "        for layer in self.conv_layers:\n",
        "            x = layer.forward(x)\n",
        "        return self.pool(x)\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(Net, self).__init__()\n",
        "        self.layers = [ManyConvMaxPool(1, 4, 1, 64, 80, stride=4),\n",
        "                       ManyConvMaxPool(2, 4, 64, 64, 3),\n",
        "                       ManyConvMaxPool(2, 4, 64, 128, 3),\n",
        "                       ManyConvMaxPool(3, 4, 128, 256, 3),\n",
        "                       ManyConvMaxPool(2, 4, 256, 512, 3)]\n",
        "        self.avgPool = nn.AvgPool1d(6) #input should be 512x6 so this outputs a 512x1\n",
        "        self.fc1 = nn.Linear(512, num_classes)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        for layer in self.layers:\n",
        "            x = layer.forward(x)\n",
        "        x = self.avgPool(x)\n",
        "        x = x.permute(0, 2, 1) #change the 512x1 to 1x512\n",
        "        x = self.fc1(x)\n",
        "        return F.log_softmax(x, dim = 2)\n",
        "\n",
        "\n",
        "class Thing():\n",
        "    def __init__(self, log_interval):\n",
        "        self.log_interval = log_interval\n",
        "        self.test_results = []\n",
        "\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        logging.debug(f'Device: {self.device}')\n",
        "        if torch.cuda.is_available():\n",
        "            logging.debug(f'we have {torch.cuda.device_count()} GPU(s)')\n",
        "\n",
        "\n",
        "    def train(self, epoch):\n",
        "        self.model.train()\n",
        "        for batch_idx, (data, target) in enumerate(self.train_loader):\n",
        "            self.optimizer.zero_grad()\n",
        "            data = data.to(self.device)\n",
        "            target = target.to(self.device)\n",
        "            data = data.requires_grad_() #set requires_grad to True for training\n",
        "            output = self.model(data)\n",
        "            output = output.permute(1, 0, 2) #original output dimensions are batchSizex1x10 \n",
        "            loss = F.nll_loss(output[0], target) #the loss functions expects a batchSizex10 input\n",
        "            loss.backward()\n",
        "            self.optimizer.step()\n",
        "            if batch_idx % self.log_interval == 0: #print training stats\n",
        "                logging.info('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                    epoch, batch_idx * len(data), len(self.train_loader.dataset),\n",
        "                    100. * batch_idx / len(self.train_loader), loss))\n",
        "\n",
        "\n",
        "    def test(self, epoch):\n",
        "        self.model.eval()\n",
        "        correct = 0\n",
        "        for data, target in self.test_loader:\n",
        "            data = data.to(self.device)\n",
        "            target = target.to(self.device)\n",
        "            output = self.model(data)\n",
        "            output = output.permute(1, 0, 2)\n",
        "            pred = output.max(2)[1] # get the index of the max log-probability\n",
        "            correct += pred.eq(target).cpu().sum().item()\n",
        "        print('\\nTest set: Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "            correct, len(self.test_loader.dataset),\n",
        "            100. * correct / len(self.test_loader.dataset)))\n",
        "        return correct / len(self.test_loader.dataset)\n",
        "\n",
        "\n",
        "    def go(self, epochs):\n",
        "        start_time = time.time()\n",
        "        for epoch in range(1, epochs + 1):\n",
        "            epoch_start_time = time.time()\n",
        "            self.train(epoch)\n",
        "            self.test_results.append(self.test(epoch))\n",
        "            self.scheduler.step()\n",
        "            logging.info('Epoch {}, epoch time: {}, total time: {} seconds'.format(epoch,\n",
        "                                                                                   int(time.time() - epoch_start_time),\n",
        "                                                                                   int(time.time() - start_time)))"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "da15r0IUGYBD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epochs=30\n",
        "segment_length=32000\n",
        "segments_per_song=4\n",
        "downsample_rate=5\n",
        "music_dir=os.path.join(MUSIC_DIR, '20sec')\n",
        "metadata=open(os.path.join(PROJECT_ROOT, '2-classes-wav.yaml'),'r')\n",
        "logging.getLogger().setLevel(logging.INFO)\n",
        "#logging.getLogger().setLevel(logging.DEBUG)\n",
        "\n",
        "songs = [Song(s) for s in yaml.safe_load(metadata)]\n",
        "\n",
        "thing = Thing(log_interval = 20)\n",
        "thing.train_set = AudioDataset([s for s in songs if s.role == 'train'],\n",
        "                                music_dir, segment_length,\n",
        "                                segments_per_song, downsample_rate)\n",
        "thing.test_set = AudioDataset([s for s in songs if s.role == 'test'],\n",
        "                                music_dir, segment_length,\n",
        "                                segments_per_song, downsample_rate)\n",
        "logging.info(f'Train set size: {len(thing.train_set)}')\n",
        "logging.info(f'Test set size: {len(thing.test_set)}')\n",
        "\n",
        "kwargs = {'num_workers': 1, 'pin_memory': True} if thing.device == 'cuda' else {}\n",
        "thing.train_loader = torch.utils.data.DataLoader(thing.train_set, batch_size = 128, shuffle = True, **kwargs)\n",
        "thing.test_loader = torch.utils.data.DataLoader(thing.test_set, batch_size = 128, shuffle = True, **kwargs)\n",
        "\n",
        "thing.model = Net(2)\n",
        "thing.model.to(thing.device)\n",
        "\n",
        "thing.optimizer = optim.Adam(thing.model.parameters(), lr = 0.01, weight_decay = 0.0001)\n",
        "thing.scheduler = optim.lr_scheduler.StepLR(thing.optimizer, step_size = int(epochs/2), gamma = 0.1)\n",
        "\n",
        "thing.go(epochs)\n",
        "print('Done')\n",
        "thing.test_results"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ill0xPTGFJL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(thing.test_results)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}