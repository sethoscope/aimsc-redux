{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Train and Test.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOXqB84v6bukFnmURmGLpba",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sethoscope/aimsc-redux/blob/master/Train_and_Test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8_zL0jUrGHFu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "import os.path\n",
        "MOUNT_POINT='/content/drive'\n",
        "if not os.path.exists(MOUNT_POINT):\n",
        "    drive.mount(MOUNT_POINT)\n",
        "PROJECT_ROOT = os.path.join(MOUNT_POINT, 'My Drive/aimsc-redux')\n",
        "MUSIC_DIR = os.path.join(PROJECT_ROOT, 'music')\n",
        "%cd {MUSIC_DIR}\n",
        "!pip install torchaudio"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oE17HsXjF2QH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import logging\n",
        "from argparse import ArgumentParser, ArgumentDefaultsHelpFormatter, FileType\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import IterableDataset\n",
        "import torchaudio\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from collections import defaultdict\n",
        "import yaml\n",
        "import random\n",
        "import time\n",
        "import os\n",
        "\n",
        "\n",
        "def split_evenly(source, keyfunc, frac):\n",
        "    '''\n",
        "    Split a sequence into two, in proportions specified by frac,\n",
        "    such that each set grouped by keyfunc is represented proportionally\n",
        "    in each split. This is used to partition a data set into train and test\n",
        "    sets, while preserving the proportion of each class. \n",
        "    '''\n",
        "    def _split_list(s, frac):\n",
        "        s = list(s)\n",
        "        random.shuffle(s)\n",
        "        point = int(frac * len(s))\n",
        "        logging.debug(f'split: {point}, {len(s) - point}')\n",
        "        return s[:point], s[point:]\n",
        "\n",
        "    m = defaultdict(set)\n",
        "    for item in source:\n",
        "        m[keyfunc(item)].add(item)\n",
        "\n",
        "    x = set([])\n",
        "    y = set([])\n",
        "    for v in m.values():\n",
        "        x1, y1 = _split_list(v, frac)\n",
        "        x.update(x1)\n",
        "        y.update(y1)\n",
        "    logging.debug(f'split total: {len(x)}, {len(y)}')\n",
        "    return list(x), list(y)\n",
        "\n",
        "# assumptions:\n",
        "#   all inputs have the same sampling frequency\n",
        "class AudioDataset(IterableDataset):\n",
        "    def __init__(self, songs, music_dir, segment_length, downsample_rate):\n",
        "        super(AudioDataset, self).__init__()\n",
        "        self.songs = songs\n",
        "        self.shuffle()\n",
        "        self.music_dir = music_dir\n",
        "        self.segment_length = segment_length # audio samples per datum\n",
        "        self.downsample_rate = downsample_rate\n",
        "\n",
        "        labels = sorted(list(set(s.label for s in songs)))   # all the labels\n",
        "        self.label_number_map = {v:i for i,v in enumerate(labels)}   # {'foo':0, 'bar':1, ...}\n",
        "\n",
        "    def num_classes(self):\n",
        "        return len(self.label_number_map.keys())\n",
        "\n",
        "    def shuffle(self):\n",
        "        random.shuffle(self.songs)\n",
        "\n",
        "    def __iter__(self):\n",
        "        start = 0\n",
        "        # TODO: hande multiple workers\n",
        "        stop = len(self.songs)\n",
        "        for i in range(start, stop):\n",
        "            song = self.songs[i]\n",
        "            for segment in song.audio_segments(self.music_dir,\n",
        "                                               self.segment_length, \n",
        "                                               self.downsample_rate):\n",
        "                yield segment, self.label_number_map[song.label]\n",
        "\n",
        "\n",
        "class Song():\n",
        "    def __init__(self, fields):\n",
        "        self.fields = fields\n",
        "        self.__dict__.update(fields)\n",
        "\n",
        "    def __repr__(self):\n",
        "        return 'Song<{}>'.format(str(list(self.fields.values())))\n",
        "\n",
        "    def audio_segments(self, music_dir, segment_length, downsample_rate):\n",
        "        (audio, samplingfreq) = torchaudio.load(os.path.join(music_dir, self.filename))\n",
        "        audio = audio.permute(1, 0) # 1×N ~ N×1\n",
        "        # downsample, and keep the amount amount of data specified\n",
        "        audio = audio[::downsample_rate]\n",
        "        num_segments = int(len(audio) / segment_length)\n",
        "        for i in range(num_segments):\n",
        "            logging.debug(f'{self.title} has {num_segments} segments')\n",
        "            yield audio[i * segment_length\n",
        "                        : (i+1) * segment_length].permute(1, 0)\n",
        "\n",
        "class ConvBn():\n",
        "    def __init__(self, in_channels, out_channels, *args, **kwargs):\n",
        "        self.conv = nn.Conv1d(in_channels, out_channels, *args, **kwargs)\n",
        "        self.bn = nn.BatchNorm1d(out_channels)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return F.relu(self.bn(self.conv(x)))\n",
        "\n",
        "class ManyConvMaxPool():\n",
        "    def __init__(self, conv_count, maxpool_kernel, in_channels, out_channels, *args, **kwargs):\n",
        "        self.pool = nn.MaxPool1d(maxpool_kernel)\n",
        "        self.conv_layers = [ConvBn(in_channels, out_channels, *args, **kwargs)]\n",
        "        for _ in range(conv_count - 1):\n",
        "            self.conv_layers.append(ConvBn(out_channels, out_channels, *args, **kwargs))\n",
        "\n",
        "    def forward(self, x):\n",
        "        for layer in self.conv_layers:\n",
        "            x = layer.forward(x)\n",
        "        return self.pool(x)\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(Net, self).__init__()\n",
        "        # M11 network from https://arxiv.org/pdf/1610.00087.pdf\n",
        "        self.layers = [ManyConvMaxPool(1, 4, 1, 64, 80, stride=4),\n",
        "                       ManyConvMaxPool(2, 4, 64, 64, 3),\n",
        "                       ManyConvMaxPool(2, 4, 64, 128, 3),\n",
        "                       ManyConvMaxPool(3, 4, 128, 256, 3),\n",
        "                       ManyConvMaxPool(2, 4, 256, 512, 3)]\n",
        "        self.avgPool = nn.AvgPool1d(6)\n",
        "        self.fc1 = nn.Linear(512, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        for layer in self.layers:\n",
        "            x = layer.forward(x)\n",
        "        x = self.avgPool(x)\n",
        "        x = x.permute(0, 2, 1) #change the 512x1 to 1x512\n",
        "        x = self.fc1(x)\n",
        "        return F.log_softmax(x, dim = 2)\n",
        "\n",
        "\n",
        "class Thing():\n",
        "    def __init__(self, log_interval):\n",
        "        self.log_interval = log_interval\n",
        "        self.test_results = []\n",
        "\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        logging.debug(f'Device: {self.device}')\n",
        "        if torch.cuda.is_available():\n",
        "            logging.debug(f'we have {torch.cuda.device_count()} GPU(s)')\n",
        "\n",
        "\n",
        "    def train(self, epoch):\n",
        "        self.model.train()\n",
        "        self.train_set.shuffle()\n",
        "        for batch_idx, (data, target) in enumerate(self.train_loader):\n",
        "            self.optimizer.zero_grad()\n",
        "            data = data.to(self.device)\n",
        "            target = target.to(self.device)\n",
        "            data = data.requires_grad_() #set requires_grad to True for training\n",
        "            output = self.model(data)\n",
        "            output = output.permute(1, 0, 2) #original output dimensions are batchSizex1x10 \n",
        "            loss = F.nll_loss(output[0], target) #the loss functions expects a batchSizex10 input\n",
        "            loss.backward()\n",
        "            self.optimizer.step()\n",
        "            if batch_idx % self.log_interval == 0: #print training stats\n",
        "                logging.info(f'Train Epoch: {epoch} \\tLoss: {loss}')\n",
        "\n",
        "    def test(self, epoch):\n",
        "        self.test_set.shuffle()\n",
        "        self.model.eval()\n",
        "        correct = 0\n",
        "        total_predictions = 0\n",
        "        for data, target in self.test_loader:\n",
        "            data = data.to(self.device)\n",
        "            target = target.to(self.device)\n",
        "            output = self.model(data)\n",
        "            output = output.permute(1, 0, 2)\n",
        "            pred = output.max(2)[1] # get the index of the max log-probability\n",
        "            total_predictions += max(pred.size())\n",
        "            correct += pred.eq(target).cpu().sum().item()\n",
        "            print('  Accuracy so far: {}/{} ({:.0f}%)'.format(\n",
        "                correct, total_predictions, 100. * correct / total_predictions))\n",
        "        accuracy = correct / total_predictions\n",
        "        print('\\nTest set: Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "            correct, total_predictions, 100. * accuracy))\n",
        "        return accuracy\n",
        "\n",
        "\n",
        "    def go(self, epochs):\n",
        "        start_time = time.time()\n",
        "        for epoch in range(1, epochs + 1):\n",
        "            epoch_start_time = time.time()\n",
        "            self.train(epoch)\n",
        "            self.test_results.append(self.test(epoch))\n",
        "            self.scheduler.step()\n",
        "            logging.info('Epoch {}, epoch time: {}, total time: {} seconds'.format(epoch,\n",
        "                                                                                   int(time.time() - epoch_start_time),\n",
        "                                                                                   int(time.time() - start_time)))"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "da15r0IUGYBD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epochs=40\n",
        "segment_length=32000\n",
        "downsample_rate=4\n",
        "music_dir=os.path.join(MUSIC_DIR, '20sec')\n",
        "metadata=open(os.path.join(PROJECT_ROOT, '2-classes-wav.yaml'),'r')\n",
        "logging.getLogger().setLevel(logging.INFO)\n",
        "#logging.getLogger().setLevel(logging.DEBUG)\n",
        "\n",
        "train_songs, test_songs = split_evenly((Song(s) for s in yaml.safe_load(metadata)),\n",
        "                                       lambda s: s.label, 0.9)\n",
        "thing = Thing(log_interval = 20)\n",
        "thing.train_set = AudioDataset(train_songs,\n",
        "                                music_dir, segment_length, downsample_rate)\n",
        "thing.test_set = AudioDataset(test_songs,\n",
        "                                music_dir, segment_length, downsample_rate)\n",
        "logging.info(f'Train set size: {len(thing.train_set.songs)} songs')\n",
        "logging.info(f'Test set size: {len(thing.test_set.songs)} songs')\n",
        "\n",
        "kwargs = {'num_workers': 1, 'pin_memory': True} if thing.device == 'cuda' else {}\n",
        "thing.train_loader = torch.utils.data.DataLoader(thing.train_set, batch_size = 128, **kwargs)\n",
        "thing.test_loader = torch.utils.data.DataLoader(thing.test_set, batch_size = 128, **kwargs)\n",
        "\n",
        "thing.model = Net(thing.train_set.num_classes())\n",
        "thing.model.to(thing.device)\n",
        "\n",
        "#thing.optimizer = optim.Adam(thing.model.parameters(), lr = 0.01, weight_decay = 0.0001)\n",
        "thing.optimizer = optim.Adam(thing.model.parameters())\n",
        "thing.scheduler = optim.lr_scheduler.StepLR(thing.optimizer, step_size = int(epochs/2), gamma = 0.1)\n",
        "\n",
        "thing.go(epochs)\n",
        "print('Done')\n",
        "thing.test_results"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ill0xPTGFJL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(thing.test_results)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}